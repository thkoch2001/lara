TODO: https://doc.rust-lang.org/rustdoc/

** database schema
*** crawl job
- get job with lease
- update lease ( can be done by work manager by observing url frontier of crawl job?
*** url frontier

**** url priority

- domain crossing hops instead of external depth
- depth in parallel to priority to have absolute crawl frontier
- signals:
  - sitemap.xml itself and linked sitemaps have constant prio 1
  - priority of find location
  - number of urls on the find location
  - number of query params
  - number of path elements
  - url origin type:
    - crawl seed
    - url is sitemap location (from robots.txt or from standard)
    - url found as link alternate feed
    - url from feed
    - url from HTML body
    - url from css/js tag
    - url from img tag
    - url from redirect of depth N

- properties
  - priority from sitemaps is between 0 < p <= 1
  - query params are worse than path elements
  - remaining depth goes down

**** url to crawl map

- stealing of work possible if crawl A already crawls an URL external to crawl B?
  Or rather work injection, if a crawl for a domain exists?

**** queries

- insert initial URL(s)
- Insert URLs found
  - only if URLs does not exist yet

- get next uncrawled url
  - order by priority
  - round robin over URLs
- set url to crawled

*** crawle archive

- get archived pages for URL
- get all archived URLs for domain below path

** crates to use
- https://crates.io/crates/scraper - HTML parsing and querying with CSS selectors
- https://crates.io/crates/anyhow - Flexible concrete Error type built on std::error::Error
- https://github.com/utkarshkukreti/select.rs - extract data from HTML
- https://crates.io/crates/rouille - mini HTTP server for status and control pages
** robots.txt

[[https://www.rfc-editor.org/rfc/rfc9309.html][RFC 9309]], [[https://developers.google.com/search/docs/crawling-indexing/robots/robots_txt][Google]], [[https://yandex.ru/support/webmaster/controlling-robot/robots-txt.html?lang=en][Yandex]] docs, [[https://www.robotstxt.org][robotstxt.org]]

Google based [[https://crates.io/crates/robotstxt][robotstxt]] does not(?) provide an object to hold a parsed
robots.txt, is from a time before [[https://datatracker.ietf.org/doc/rfc9309/][RFC 9309]] and seems to be very "unrusty"
(much mutable global state). After all it's a simple transliteration from C++.

- [[https://crates.io/crates/texting_robots][texting_robots]]
  - forked by Spire-rs' [[https://github.com/spire-rs/kit/tree/main/exclusion][kit/exclusion]]
- [[https://crates.io/crates/robotparser][robotparser-rs]]
  - forked by [[https://github.com/spider-rs/spider/blob/4cded306fb34e32f6806998cbf28e8558ceaeb13/spider/src/packages/robotparser/parser.rs][spider]]
- [[https://crates.io/crates/robots_txt][robots_txt]] - unstabke, WIP, +4y

** sitemaps

- https://developers.google.com/search/docs/crawling-indexing/sitemaps
- https://sitemaps.org
- https://en.m.wikipedia.org/wiki/Sitemaps

*** Crates

- https://crates.io/crates/sitemap xml-rs, old but 8 dependents
- https://crates.io/crates/sitemap-iter roxmltree (2022-02)
- https://crates.io/crates/sitemaps quick-xml (2024-06), experimental learning project
- https://crates.io/crates/wls - check for ideas
- https://crates.io/crates/sitemapo quick-xml (2023-07), dead repo

** TODO
- search topics
  - "focused crawling"
- https://developers.google.com/search/docs/crawling-indexing
*** Canonical Link Element
- https://en.wikipedia.org/wiki/Canonical_link_element
*** URL normalization
- https://crates.io/crates/urlnorm 
- https://en.wikipedia.org/wiki/URI_normalization
  - "Schonfeld et al. (2006) present a heuristic called DustBuster for detecting DUST (different URIs with similar text)"
**** remove tracking URL parameters
- https://github.com/brave/brave-browser/wiki/Query-String-Filter
- https://gitlab.com/ClearURLs/ClearUrls
  - https://gitlab.com/ClearURLs/rules -> data.min.json -> "globalRules"

** compiling with openssl on Debian

https://github.com/sfackler/rust-openssl/issues/2333

sudo apt install libc6-dev libssl-dev
sudo ln -s /usr/include/x86_64-linux-gnu/openssl/opensslconf.h /usr/include/openssl/opensslconf.h
sudo ln -s /usr/include/x86_64-linux-gnu/openssl/configuration.h /usr/include/openssl/configuration.h

** interesting stuff

- [[https://brave.com/static-assets/files/goggles.pdf][GOGGLES: Democracy dies in darkness, and so does the Web]] paper by Brave Search Team, via Spyglass
  - https://videos.cern.ch/record/2295289
  - https://www.afaik.de/nona-werbefreie-suchmaschine-aus-deutschland/
- https://github.com/spyglass-search
- https://github.com/iipc - International Internet Preservation Consortium
  - https://github.com/iipc/openwayback/wiki/OpenWayback-Users

*** postgres

- https://www.postgresguide.com
- https://github.com/elierotenberg/coding-styles/blob/master/postgres.md

*** crates
- https://crates.io/crates/fetcher Automatic news fetching and parsing
- https://crates.io/crates/httptest HTTP testing facilities including a mock server
- https://github.com/lipanski/mockito HTTP mocking for Rust! https://zupzup.org/rust-http-testing/
- https://crates.io/crates/tempfile
- https://crates.io/crates/pretty_assertions
- https://crates.io/crates/nonzero
- https://crates.io/crates/webpage
- https://crates.io/crates/warc
- https://crates.io/crates/feedfinder Auto-discovery of feeds in HTML content
- https://crates.io/crates/governor - A rate-limiting implementation in Rust
- https://crates.io/crates/thiserror
- https://crates.io/crates/tracing https://gist.github.com/oliverdaff/d1d5e5bc1baba087b768b89ff82dc3ec
- https://crates.io/crates/governor - complex rate limiting algorithm, used in spyglass-search/netrunner
- https://crates.io/crates/apalis - background job processing
- https://github.com/poem-web/poem - web framework
- https://crates.io/crates/metrics-dashboard uses poem and metrics
- https://crates.io/crates/metrics_server
- https://crates.io/crates/memberlist-core - Gossip protocol for cluster membership
- displaydoc derive macro for the standard libraryâ€™s core::fmt::Display, especially for errors
- scopeguard run a given closure when it goes out of scope (like defer in D)

*** HTML content / article extraction

- https://github.com/grangier/python-goose
- https://pkg.go.dev/github.com/thatguystone/swan
- https://crates.io/crates/extrablatt
- https://crates.io/crates/mozilla-readability
